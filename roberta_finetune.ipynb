{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devanshj/miniconda3/envs/anlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForMultipleChoice, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import json_lines\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleChoiceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask, label = self.data[idx]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_map = {'A':0,'B':1,'C':2,'D':3,'E':4}\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'rb') as f: \n",
    "        for item in json_lines.reader(f):\n",
    "            data.append(item)\n",
    "\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        question = item['question']['stem']\n",
    "        options = [_['text'] for _ in item['question']['choices']]\n",
    "        examples = []\n",
    "        for option in options:\n",
    "            text = question + \" \" + option\n",
    "            encoded = tokenizer.encode_plus(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            examples.append(encoded)\n",
    "    \n",
    "        input_ids = torch.stack([example['input_ids'] for example in examples]).squeeze()\n",
    "        attention_mask = torch.stack([example['attention_mask'] for example in examples]).squeeze()\n",
    "\n",
    "        label = torch.tensor(answer_map[item['answerKey']])\n",
    "\n",
    "        processed_data.append((input_ids, attention_mask, label))\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.bias', 'roberta.pooler.dense.bias', 'classifier.weight', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForMultipleChoice.from_pretrained('roberta-large')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter? throw\n",
      "A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter? bit\n",
      "A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter? gallon\n",
      "A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter? mouse\n",
      "A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter? hole\n",
      "What comes in many different sizes but is always only 1 foot long? object\n",
      "What comes in many different sizes but is always only 1 foot long? shoe\n",
      "What comes in many different sizes but is always only 1 foot long? footing\n",
      "What comes in many different sizes but is always only 1 foot long? grave\n",
      "What comes in many different sizes but is always only 1 foot long? column\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data(\"data/rs_train.jsonl\")\n",
    "valid_data = load_data(\"data/rs_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultipleChoiceDataset(train_data)\n",
    "valid_dataset = MultipleChoiceDataset(valid_data)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devanshj/miniconda3/envs/anlp/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 3\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultipleChoiceModelOutput(loss=tensor(1.6510, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0060, -0.0574, -0.1595, -0.1085, -0.1472],\n",
      "        [-0.0915, -0.1951, -0.1928, -0.1051, -0.0818],\n",
      "        [-0.2362, -0.0950, -0.3088, -0.2688, -0.2323],\n",
      "        [ 0.0471, -0.0261,  0.1030,  0.0428, -0.1368]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###0####: Average loss: 0.016509516239166258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:20,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###100####: Average loss: 1.496451369524002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:40,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###200####: Average loss: 1.0525232756137848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [06:59,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###300####: Average loss: 0.9923830005526543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [09:17,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###400####: Average loss: 0.8958130796253682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [11:36,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###500####: Average loss: 0.7830511924624443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [13:55,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###600####: Average loss: 0.7765758153051138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [16:13,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###700####: Average loss: 0.7270216728420928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [18:32,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###800####: Average loss: 0.7393367589978151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [20:18,  1.39s/it]\n",
      "100%|██████████| 256/256 [02:03<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.9099054373223484, Validation accuracy: 0.5935357492654261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultipleChoiceModelOutput(loss=tensor(0.0423, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3965, -4.6109, -5.1899, -3.7595,  4.5028],\n",
      "        [-4.6873, -5.3800, -0.6399, -5.4474, -4.7167],\n",
      "        [-3.6800, -4.4706,  2.3691,  4.4511, -5.8743],\n",
      "        [-5.4509, -5.7377, -3.4823,  4.9380, -4.7760]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###0####: Average loss: 0.000422726534307003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:19,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###100####: Average loss: 0.5509661382995545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:38,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###200####: Average loss: 0.5361963753920281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [06:56,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###300####: Average loss: 0.5459809051523916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [09:15,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###400####: Average loss: 0.572009013880379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [11:33,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###500####: Average loss: 0.42549232192061026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [13:52,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###600####: Average loss: 0.5884837852175951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [16:10,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###700####: Average loss: 0.41253565587307095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [18:29,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###800####: Average loss: 0.4220320232921949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [20:15,  1.38s/it]\n",
      "100%|██████████| 256/256 [02:03<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.5041741789562331, Validation accuracy: 0.6131243878550441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultipleChoiceModelOutput(loss=tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-5.7757,  6.5004, -7.7905, -8.0654, -5.7249],\n",
      "        [-3.6226, -0.0195,  2.1777, -1.3064, -4.3619],\n",
      "        [ 7.8295, -8.3567, -3.4837, -7.8009, -8.4542],\n",
      "        [-5.1161, -7.9450, -8.1659, -8.3911,  4.9216]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###0####: Average loss: 0.00034146346151828764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:19,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###100####: Average loss: 0.2507724482954654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [04:38,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###200####: Average loss: 0.3621581985198327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [06:56,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###300####: Average loss: 0.2515381439379149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [09:15,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###400####: Average loss: 0.20269997735214018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [11:33,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###500####: Average loss: 0.24167063964106064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [13:52,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###600####: Average loss: 0.33257313119179455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [16:11,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###700####: Average loss: 0.4012812370620895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [18:29,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###800####: Average loss: 0.32189257025577717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "878it [20:15,  1.38s/it]\n",
      "100%|██████████| 256/256 [02:03<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.2950253478745673, Validation accuracy: 0.6366307541625857\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.save_pretrained('model_{}_directory'.format(epoch))\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    average_loss = 0\n",
    "    for index, batch in tqdm(enumerate(train_loader)):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        if index ==0:\n",
    "            print(outputs)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        average_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if index%100==0:\n",
    "            print(\"###{}####: Average loss: {}\".format(index,average_loss / 100))\n",
    "            average_loss = 0\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    for batch in tqdm(valid_loader):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"]\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        preds.extend(torch.argmax(logits, dim=1).detach().cpu().numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    print(f'Epoch: {epoch+1}, Train loss: {avg_train_loss}, Validation accuracy: {acc}')\n",
    "    model.save_pretrained('model_{}_directory'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
